import os
import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from typing import Dict, List, Any, Optional, Tuple
import torch
import yaml
import json
import subprocess
from tqdm import tqdm


class HardwareDeployer:
    """ç¡¬ä»¶éƒ¨ç½²ç®¡ç†å™¨"""

    def __init__(self, config: Dict, model_path: str = None):
        self.config = config
        self.model_path = model_path

        # ç¡¬ä»¶å¹³å°é…ç½®
        self.hardware_platforms = self._initialize_hardware_platforms()

        # éƒ¨ç½²ç»“æœ
        self.deployment_results = {}

    def _initialize_hardware_platforms(self) -> Dict[str, Dict]:
        """åˆå§‹åŒ–ç¡¬ä»¶å¹³å°é…ç½®"""
        platforms = {
            'nvidia_jetson_nano': {
                'name': 'NVIDIA Jetson Nano',
                'architecture': 'ARM Cortex-A57 + 128-core NVIDIA GPU',
                'memory': '4GB LPDDR4',
                'power_consumption': '5-10W',
                'supported_hardware': ['CPU', 'GPU'],
                'deployment_script': 'deploy_scripts/jetson_deploy.sh',
                'performance_factor': 1.0  # åŸºå‡†æ€§èƒ½
            },
            'raspberry_pi_4': {
                'name': 'Raspberry Pi 4',
                'architecture': 'ARM Cortex-A72',
                'memory': '4GB/8GB LPDDR4',
                'power_consumption': '3-7W',
                'supported_hardware': ['CPU'],
                'deployment_script': 'deploy_scripts/raspberry_deploy.sh',
                'performance_factor': 0.6  # ç›¸å¯¹äºJetsonçš„æ€§èƒ½
            },
            'x86_embedded': {
                'name': 'x86 Embedded Platform',
                'architecture': 'Intel Atom/Celeron',
                'memory': '8GB DDR4',
                'power_consumption': '10-15W',
                'supported_hardware': ['CPU'],
                'deployment_script': 'deploy_scripts/x86_deploy.sh',
                'performance_factor': 0.8
            },
            'fpga_accelerator': {
                'name': 'FPGA Accelerator Board',
                'architecture': 'Xilinx/Intel FPGA',
                'memory': 'DDR4 + On-chip Memory',
                'power_consumption': '5-20W',
                'supported_hardware': ['CPU', 'FPGA'],
                'deployment_script': 'deploy_scripts/fpga_deploy.sh',
                'performance_factor': 1.2  # ç‰¹å®šä»»åŠ¡ä¸Šæ€§èƒ½æ›´å¥½
            }
        }
        return platforms

    def deploy_model(self, platform: str, deployment_mode: str = 'simulation') -> Dict[str, Any]:
        """
        éƒ¨ç½²æ¨¡å‹åˆ°ç¡¬ä»¶å¹³å°

        Args:
            platform: ç¡¬ä»¶å¹³å°
            deployment_mode: éƒ¨ç½²æ¨¡å¼ ('simulation', 'real')

        Returns:
            deployment_results: éƒ¨ç½²ç»“æœ
        """
        print(f"ğŸš€ å¼€å§‹éƒ¨ç½²åˆ° {self.hardware_platforms[platform]['name']}...")

        if platform not in self.hardware_platforms:
            raise ValueError(f"ä¸æ”¯æŒçš„ç¡¬ä»¶å¹³å°: {platform}")

        platform_info = self.hardware_platforms[platform]

        if deployment_mode == 'real':
            results = self._real_deployment(platform, platform_info)
        else:
            results = self._simulation_deployment(platform, platform_info)

        self.deployment_results[platform] = results
        return results

    def _real_deployment(self, platform: str, platform_info: Dict) -> Dict[str, Any]:
        """çœŸå®ç¡¬ä»¶éƒ¨ç½²"""
        print(f"  æ‰§è¡ŒçœŸå®ç¡¬ä»¶éƒ¨ç½²...")

        # æ£€æŸ¥éƒ¨ç½²è„šæœ¬æ˜¯å¦å­˜åœ¨
        deploy_script = platform_info['deployment_script']
        if not os.path.exists(deploy_script):
            print(f"  âš ï¸ éƒ¨ç½²è„šæœ¬ä¸å­˜åœ¨: {deploy_script}ï¼Œä½¿ç”¨æ¨¡æ‹Ÿéƒ¨ç½²")
            return self._simulation_deployment(platform, platform_info)

        try:
            # æ‰§è¡Œéƒ¨ç½²è„šæœ¬
            result = subprocess.run(
                ['bash', deploy_script, self.model_path],
                capture_output=True, text=True, timeout=300
            )

            if result.returncode == 0:
                print(f"  âœ… éƒ¨ç½²è„šæœ¬æ‰§è¡ŒæˆåŠŸ")
                # è§£æéƒ¨ç½²ç»“æœ
                deployment_results = self._parse_deployment_output(result.stdout)
            else:
                print(f"  âŒ éƒ¨ç½²è„šæœ¬æ‰§è¡Œå¤±è´¥: {result.stderr}")
                deployment_results = self._simulation_deployment(platform, platform_info)

        except subprocess.TimeoutExpired:
            print(f"  âŒ éƒ¨ç½²è„šæœ¬æ‰§è¡Œè¶…æ—¶")
            deployment_results = self._simulation_deployment(platform, platform_info)
        except Exception as e:
            print(f"  âŒ éƒ¨ç½²è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            deployment_results = self._simulation_deployment(platform, platform_info)

        return deployment_results

    def _simulation_deployment(self, platform: str, platform_info: Dict) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿç¡¬ä»¶éƒ¨ç½²ï¼ˆç”¨äºæµ‹è¯•å’Œå¼€å‘ï¼‰"""
        print(f"  æ‰§è¡Œæ¨¡æ‹Ÿç¡¬ä»¶éƒ¨ç½²...")

        # æ¨¡æ‹Ÿéƒ¨ç½²è¿‡ç¨‹
        time.sleep(2)  # æ¨¡æ‹Ÿéƒ¨ç½²æ—¶é—´

        # åŸºäºå¹³å°æ€§èƒ½å› å­è°ƒæ•´é¢„æœŸæ€§èƒ½
        performance_factor = platform_info['performance_factor']

        # æ¨¡æ‹Ÿæ€§èƒ½æµ‹è¯•ç»“æœ
        test_results = self._run_simulation_tests(platform, performance_factor)

        deployment_results = {
            'platform': platform,
            'platform_name': platform_info['name'],
            'deployment_status': 'success',
            'deployment_mode': 'simulation',
            'deployment_time': 2.0,
            'performance_factor': performance_factor,
            'test_results': test_results,
            'resource_usage': self._simulate_resource_usage(platform_info),
            'power_measurements': self._simulate_power_measurements(platform_info)
        }

        return deployment_results

    def _run_simulation_tests(self, platform: str, performance_factor: float) -> Dict[str, Any]:
        """è¿è¡Œæ¨¡æ‹Ÿæ€§èƒ½æµ‹è¯•"""
        from data.datasets.embedded_dag_generator import EmbeddedDAGGenerator
        from environments.embedded_scheduling_env import EmbeddedSchedulingEnvironment
        from utils.metrics import SchedulingMetrics

        dag_generator = EmbeddedDAGGenerator(self.config)
        env = EmbeddedSchedulingEnvironment(self.config)
        metrics_calculator = SchedulingMetrics()

        test_dags = [dag_generator.generate() for _ in range(10)]

        makespans = []
        energies = []
        inference_times = []

        for dag in test_dags:
            # æ¨¡æ‹Ÿæ¨ç†æ—¶é—´ï¼ˆè€ƒè™‘ç¡¬ä»¶æ€§èƒ½å› å­ï¼‰
            start_time = time.time()

            state = env.reset(dag)
            done = False

            while not done:
                # åœ¨çœŸå®éƒ¨ç½²ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨éƒ¨ç½²çš„æ¨¡å‹è¿›è¡Œæ¨ç†
                # æ¨¡æ‹Ÿæ¨ç†å»¶è¿Ÿ
                time.sleep(0.001 * (1.0 / performance_factor))  # è°ƒæ•´å»¶è¿ŸåŸºäºæ€§èƒ½å› å­

                # æ¨¡æ‹ŸåŠ¨ä½œé€‰æ‹©ï¼ˆéšæœºï¼‰
                available_actions = env.get_available_actions()
                action = np.random.choice(available_actions)

                state, reward, done, info = env.step(action)

            inference_time = time.time() - start_time
            metrics = metrics_calculator.calculate_metrics(env)

            makespans.append(metrics['makespan'] * (1.0 / performance_factor))
            energies.append(metrics['energy_consumption'] * performance_factor)  # èƒ½è€—ä¸æ€§èƒ½å› å­ç›¸å…³
            inference_times.append(inference_time)

        return {
            'avg_makespan': np.mean(makespans),
            'std_makespan': np.std(makespans),
            'avg_energy': np.mean(energies),
            'avg_inference_time': np.mean(inference_times),
            'throughput': len(test_dags) / np.sum(inference_times)  # ä»»åŠ¡/ç§’
        }

    def _simulate_resource_usage(self, platform_info: Dict) -> Dict[str, float]:
        """æ¨¡æ‹Ÿèµ„æºä½¿ç”¨æƒ…å†µ"""
        return {
            'cpu_usage': np.random.uniform(0.3, 0.8),
            'memory_usage': np.random.uniform(0.2, 0.6),
            'gpu_usage': 0.0 if 'GPU' not in platform_info['supported_hardware'] else np.random.uniform(0.4, 0.9),
            'fpga_usage': 0.0 if 'FPGA' not in platform_info['supported_hardware'] else np.random.uniform(0.5, 0.95)
        }

    def _simulate_power_measurements(self, platform_info: Dict) -> Dict[str, float]:
        """æ¨¡æ‹ŸåŠŸè€—æµ‹é‡"""
        base_power = {
            'nvidia_jetson_nano': 5.0,
            'raspberry_pi_4': 3.0,
            'x86_embedded': 8.0,
            'fpga_accelerator': 6.0
        }

        platform_key = [k for k, v in self.hardware_platforms.items() if v['name'] == platform_info['name']][0]
        base = base_power.get(platform_key, 5.0)

        return {
            'idle_power': base,
            'average_power': base * 1.3,
            'peak_power': base * 1.8,
            'energy_efficiency': np.random.uniform(0.7, 0.9)  # èƒ½æ•ˆæ¯”
        }

    def _parse_deployment_output(self, output: str) -> Dict[str, Any]:
        """è§£æéƒ¨ç½²è„šæœ¬è¾“å‡º"""
        # è¿™é‡Œåº”è¯¥æ ¹æ®å®é™…éƒ¨ç½²è„šæœ¬çš„è¾“å‡ºæ ¼å¼è¿›è¡Œè§£æ
        # ç®€åŒ–å®ç°
        return {
            'deployment_status': 'success',
            'deployment_mode': 'real',
            'output_summary': output[:200] + '...' if len(output) > 200 else output
        }

    def deploy_to_all_platforms(self, deployment_mode: str = 'simulation') -> Dict[str, Any]:
        """éƒ¨ç½²åˆ°æ‰€æœ‰æ”¯æŒçš„ç¡¬ä»¶å¹³å°"""
        print("=" * 80)
        print("ğŸ”§ å¼€å§‹å¤šå¹³å°éƒ¨ç½²")
        print("=" * 80)

        for platform in self.hardware_platforms.keys():
            self.deploy_model(platform, deployment_mode)

        # ç”Ÿæˆéƒ¨ç½²æ¯”è¾ƒæŠ¥å‘Š
        self._generate_deployment_report()

        return self.deployment_results

    def _generate_deployment_report(self):
        """ç”Ÿæˆéƒ¨ç½²æŠ¥å‘Š"""
        print("\n" + "=" * 80)
        print("ğŸ“‹ ç¡¬ä»¶éƒ¨ç½²æŠ¥å‘Š")
        print("=" * 80)

        deployment_data = []

        for platform, results in self.deployment_results.items():
            platform_name = self.hardware_platforms[platform]['name']
            test_results = results.get('test_results', {})

            row = {
                'Platform': platform_name,
                'Deployment Status': results.get('deployment_status', 'unknown'),
                'Mode': results.get('deployment_mode', 'simulation'),
                'Avg Makespan (ms)': test_results.get('avg_makespan', 0),
                'Avg Energy': test_results.get('avg_energy', 0),
                'Throughput (tasks/s)': test_results.get('throughput', 0),
                'Avg Inference Time (s)': test_results.get('avg_inference_time', 0)
            }
            deployment_data.append(row)

        # æ‰“å°éƒ¨ç½²ç»“æœè¡¨æ ¼
        df = pd.DataFrame(deployment_data)
        print("\néƒ¨ç½²æ€§èƒ½æ¯”è¾ƒ:")
        print(df.to_string(index=False))

        # ä¿å­˜éƒ¨ç½²ç»“æœ
        self._save_deployment_results()

        # ç”Ÿæˆæ€§èƒ½æ¯”è¾ƒå›¾è¡¨
        self._plot_deployment_comparison()

    def _save_deployment_results(self):
        """ä¿å­˜éƒ¨ç½²ç»“æœ"""
        os.makedirs('results/deployment', exist_ok=True)

        # ä¿å­˜è¯¦ç»†ç»“æœ
        with open('results/deployment/deployment_results.json', 'w') as f:
            json.dump(self.deployment_results, f, indent=2, default=str)

        # ä¿å­˜æ‘˜è¦
        summary_data = []
        for platform, results in self.deployment_results.items():
            platform_name = self.hardware_platforms[platform]['name']
            test_results = results.get('test_results', {})

            summary_data.append({
                'platform': platform_name,
                'deployment_status': results.get('deployment_status', 'unknown'),
                'avg_makespan': test_results.get('avg_makespan', 0),
                'avg_energy': test_results.get('avg_energy', 0),
                'throughput': test_results.get('throughput', 0),
                'performance_factor': results.get('performance_factor', 1.0)
            })

        df = pd.DataFrame(summary_data)
        df.to_csv('results/deployment/deployment_summary.csv', index=False)

        print("âœ… éƒ¨ç½²ç»“æœå·²ä¿å­˜è‡³ results/deployment/")

    def _plot_deployment_comparison(self):
        """ç»˜åˆ¶éƒ¨ç½²æ€§èƒ½æ¯”è¾ƒå›¾"""
        if not self.deployment_results:
            return

        platforms = []
        makespans = []
        energies = []
        throughputs = []

        for platform, results in self.deployment_results.items():
            platform_name = self.hardware_platforms[platform]['name']
            test_results = results.get('test_results', {})

            platforms.append(platform_name)
            makespans.append(test_results.get('avg_makespan', 0))
            energies.append(test_results.get('avg_energy', 0))
            throughputs.append(test_results.get('throughput', 0))

        # åˆ›å»ºæ¯”è¾ƒå›¾è¡¨
        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))

        # å®Œæˆæ—¶é—´æ¯”è¾ƒ
        bars1 = ax1.bar(platforms, makespans, alpha=0.7, color='skyblue')
        ax1.set_title('å¹³å‡å®Œæˆæ—¶é—´æ¯”è¾ƒ')
        ax1.set_ylabel('å®Œæˆæ—¶é—´ (ms)')
        ax1.tick_params(axis='x', rotation=45)

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars1:
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width() / 2., height + 5,
                     f'{height:.1f}', ha='center', va='bottom')

        # èƒ½è€—æ¯”è¾ƒ
        bars2 = ax2.bar(platforms, energies, alpha=0.7, color='lightcoral')
        ax2.set_title('å¹³å‡èƒ½è€—æ¯”è¾ƒ')
        ax2.set_ylabel('èƒ½è€—')
        ax2.tick_params(axis='x', rotation=45)

        # ååé‡æ¯”è¾ƒ
        bars3 = ax3.bar(platforms, throughputs, alpha=0.7, color='lightgreen')
        ax3.set_title('ååé‡æ¯”è¾ƒ')
        ax3.set_ylabel('ååé‡ (ä»»åŠ¡/ç§’)')
        ax3.tick_params(axis='x', rotation=45)

        plt.tight_layout()
        plt.savefig('results/deployment/platform_comparison.png', dpi=300, bbox_inches='tight')
        plt.close()

        print("âœ… éƒ¨ç½²æ¯”è¾ƒå›¾è¡¨å·²ä¿å­˜")

    def generate_deployment_guide(self):
        """ç”Ÿæˆéƒ¨ç½²æŒ‡å—"""
        print("\n" + "=" * 80)
        print("ğŸ“– ç¡¬ä»¶éƒ¨ç½²æŒ‡å—")
        print("=" * 80)

        guide = {
            'overview': 'åµŒå…¥å¼æ™ºèƒ½è½¯ä»¶å¹¶è¡Œä¼˜åŒ–ç³»ç»Ÿç¡¬ä»¶éƒ¨ç½²æŒ‡å—',
            'supported_platforms': list(self.hardware_platforms.keys()),
            'deployment_steps': [
                "1. å‡†å¤‡ç›®æ ‡ç¡¬ä»¶å¹³å°",
                "2. å®‰è£…å¿…è¦çš„ä¾èµ–åº“ (PyTorch, NumPy, ç­‰)",
                "3. éƒ¨ç½²æ¨¡å‹æ–‡ä»¶åˆ°ç›®æ ‡è®¾å¤‡",
                "4. é…ç½®ç¯å¢ƒå‚æ•°",
                "5. è¿è¡ŒéªŒè¯æµ‹è¯•",
                "6. é›†æˆåˆ°ç›®æ ‡åº”ç”¨ç¨‹åº"
            ],
            'performance_optimization_tips': [
                "ä½¿ç”¨é‡åŒ–æŠ€æœ¯å‡å°‘æ¨¡å‹å¤§å°",
                "åˆ©ç”¨ç¡¬ä»¶ç‰¹å®šåŠ é€Ÿåº“",
                "ä¼˜åŒ–å†…å­˜è®¿é—®æ¨¡å¼",
                "è°ƒæ•´æ‰¹å¤„ç†å¤§å°å¹³è¡¡å»¶è¿Ÿå’Œååé‡"
            ],
            'troubleshooting': [
                "æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§",
                "éªŒè¯ç¡¬ä»¶å…¼å®¹æ€§",
                "ç›‘æ§èµ„æºä½¿ç”¨æƒ…å†µ",
                "æŸ¥çœ‹ç³»ç»Ÿæ—¥å¿—è·å–é”™è¯¯ä¿¡æ¯"
            ]
        }

        # ä¿å­˜éƒ¨ç½²æŒ‡å—
        os.makedirs('docs', exist_ok=True)
        with open('docs/deployment_guide.json', 'w') as f:
            json.dump(guide, f, indent=2)

        # ç”ŸæˆMarkdownæ ¼å¼çš„æŒ‡å—
        self._generate_markdown_guide(guide)

        print("âœ… éƒ¨ç½²æŒ‡å—å·²ç”Ÿæˆè‡³ docs/ ç›®å½•")

    def _generate_markdown_guide(self, guide: Dict):
        """ç”ŸæˆMarkdownæ ¼å¼çš„éƒ¨ç½²æŒ‡å—"""
        markdown_content = f"""# {guide['overview']}

## æ”¯æŒçš„ç¡¬ä»¶å¹³å°

{', '.join(guide['supported_platforms'])}

## éƒ¨ç½²æ­¥éª¤

"""

        for step in guide['deployment_steps']:
            markdown_content += f"{step}\n\n"

        markdown_content += "## æ€§èƒ½ä¼˜åŒ–å»ºè®®\n\n"
        for tip in guide['performance_optimization_tips']:
            markdown_content += f"- {tip}\n"

        markdown_content += "\n## æ•…éšœæ’é™¤\n\n"
        for item in guide['troubleshooting']:
            markdown_content += f"- {item}\n"

        markdown_content += f"""

## éƒ¨ç½²æ€§èƒ½ç»“æœ

ä»¥ä¸‹æ˜¯å„ç¡¬ä»¶å¹³å°çš„æ€§èƒ½æµ‹è¯•ç»“æœï¼š

| å¹³å° | å¹³å‡å®Œæˆæ—¶é—´ (ms) | å¹³å‡èƒ½è€— | ååé‡ (ä»»åŠ¡/ç§’) |
|------|------------------|----------|-----------------|
"""

        for platform, results in self.deployment_results.items():
            platform_name = self.hardware_platforms[platform]['name']
            test_results = results.get('test_results', {})

            markdown_content += f"| {platform_name} | {test_results.get('avg_makespan', 0):.1f} | {test_results.get('avg_energy', 0):.1f} | {test_results.get('throughput', 0):.1f} |\n"

        with open('docs/deployment_guide.md', 'w') as f:
            f.write(markdown_content)


def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡Œç¡¬ä»¶éƒ¨ç½²"""
    # åŠ è½½é…ç½®
    with open('configs/default_config.yaml', 'r') as f:
        config = yaml.safe_load(f)

    # åˆ›å»ºéƒ¨ç½²å™¨
    deployer = HardwareDeployer(config, model_path='checkpoints/best_model.pth')

    # éƒ¨ç½²åˆ°æ‰€æœ‰å¹³å°ï¼ˆæ¨¡æ‹Ÿæ¨¡å¼ï¼‰
    results = deployer.deploy_to_all_platforms(deployment_mode='simulation')

    # ç”Ÿæˆéƒ¨ç½²æŒ‡å—
    deployer.generate_deployment_guide()

    print("\nğŸ‰ ç¡¬ä»¶éƒ¨ç½²å®Œæˆï¼")


if __name__ == "__main__":
    main()