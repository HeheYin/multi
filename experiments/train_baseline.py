import os
import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from typing import Dict, List, Any, Optional
import json
from tqdm import tqdm

from environments.embedded_scheduling_env import EmbeddedSchedulingEnvironment
from data.datasets.embedded_dag_generator import EmbeddedDAGGenerator
from utils.metrics import SchedulingMetrics
from utils.logger import ExperimentLogger


class BaselineTrainer:
    """åŸºçº¿ç®—æ³•è®­ç»ƒå™¨"""

    def __init__(self, config: Dict):
        self.config = config
        self.logger = ExperimentLogger('baseline_training')
        self.metrics_calculator = SchedulingMetrics()

        # åˆå§‹åŒ–ç¯å¢ƒ
        self.env = EmbeddedSchedulingEnvironment(config)

        # åˆå§‹åŒ–æ•°æ®ç”Ÿæˆå™¨
        self.dag_generator = EmbeddedDAGGenerator(config)

        # è®­ç»ƒç»“æœ
        self.training_results = {}
        self.baseline_performance = {}

    def train_heft(self, num_episodes: int = 100) -> Dict[str, Any]:
        """è®­ç»ƒHEFTç®—æ³•ï¼ˆå®é™…ä¸Šæ˜¯è¿è¡Œå¹¶æ”¶é›†æ€§èƒ½æ•°æ®ï¼‰"""
        print("ğŸš€ å¼€å§‹HEFTåŸºçº¿æ€§èƒ½è¯„ä¼°...")

        results = {
            'makespans': [],
            'energy_consumptions': [],
            'load_balances': [],
            'deadline_satisfactions': [],
            'training_time': 0
        }

        start_time = time.time()

        for episode in tqdm(range(num_episodes), desc="HEFT"):
            # ç”ŸæˆéšæœºDAG
            dag = self.dag_generator.generate()

            # è¿è¡ŒHEFTè°ƒåº¦
            metrics = self._run_heft_scheduling(dag)

            # è®°å½•ç»“æœ
            results['makespans'].append(metrics['makespan'])
            results['energy_consumptions'].append(metrics['energy_consumption'])
            results['load_balances'].append(metrics['load_balance'])
            results['deadline_satisfactions'].append(metrics['deadline_satisfaction'])

        results['training_time'] = time.time() - start_time

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        results['avg_makespan'] = np.mean(results['makespans'])
        results['std_makespan'] = np.std(results['makespans'])
        results['avg_energy'] = np.mean(results['energy_consumptions'])
        results['avg_load_balance'] = np.mean(results['load_balances'])
        results['avg_deadline_satisfaction'] = np.mean(results['deadline_satisfactions'])

        self.baseline_performance['HEFT'] = results
        print(f"âœ… HEFTè¯„ä¼°å®Œæˆ - å¹³å‡å®Œæˆæ—¶é—´: {results['avg_makespan']:.2f} ms")

        return results

    def _run_heft_scheduling(self, dag) -> Dict[str, float]:
        """è¿è¡ŒHEFTè°ƒåº¦ç®—æ³•"""
        # é‡ç½®ç¯å¢ƒ
        state = self.env.reset(dag)

        # HEFTç®—æ³•æ ¸å¿ƒé€»è¾‘
        task_sequence = self._heft_task_ordering(dag)
        hardware_mapping = self._heft_processor_selection(dag, task_sequence)

        # æ‰§è¡Œè°ƒåº¦
        done = False
        while not done:
            # å¯¹äºHEFTï¼Œæˆ‘ä»¬æŒ‰ç…§é¢„è®¡ç®—çš„æ˜ å°„æ‰§è¡Œ
            current_task_id = self._get_next_heft_task(task_sequence)
            if current_task_id is None:
                # æ²¡æœ‰æ›´å¤šä»»åŠ¡ï¼Œæ¨è¿›æ—¶é—´
                self.env._advance_time()
                done = self.env.is_done()
                continue

            # è·å–é¢„åˆ†é…çš„å¤„ç†æœº
            hardware_idx = hardware_mapping.get(current_task_id, 0)
            action = hardware_idx

            state, reward, done, info = self.env.step(action)

        # æ”¶é›†æŒ‡æ ‡
        metrics = self.metrics_calculator.calculate_metrics(self.env)
        return metrics

    def _heft_task_ordering(self, dag) -> List[int]:
        """HEFTä»»åŠ¡æ’åºï¼ˆå‘ä¸Šæ’åï¼‰"""
        # è®¡ç®—å‘ä¸Šæ’å
        upward_ranks = self._calculate_upward_ranks(dag)

        # æŒ‰å‘ä¸Šæ’åé™åºæ’åº
        task_order = sorted(upward_ranks.keys(),
                            key=lambda x: upward_ranks[x],
                            reverse=True)

        return task_order

    def _calculate_upward_ranks(self, dag) -> Dict[int, float]:
        """è®¡ç®—å‘ä¸Šæ’å"""
        upward_ranks = {}
        visited = set()

        def compute_rank(task_id):
            if task_id in visited:
                return upward_ranks[task_id]

            visited.add(task_id)

            # æ‰¾åˆ°åç»§ä»»åŠ¡
            successors = self._get_successors(dag, task_id)

            if not successors:
                # é€€å‡ºä»»åŠ¡ï¼Œæ’åä¸ºå¹³å‡æ‰§è¡Œæ—¶é—´
                task = self._get_task_by_id(dag, task_id)
                avg_execution = np.mean(list(task.computation_cost.values())) if task.computation_cost else 10.0
                upward_ranks[task_id] = avg_execution
            else:
                # æ’å = å¹³å‡æ‰§è¡Œæ—¶é—´ + max(åç»§æ’å + é€šä¿¡æˆæœ¬)
                task = self._get_task_by_id(dag, task_id)
                avg_execution = np.mean(list(task.computation_cost.values())) if task.computation_cost else 10.0

                max_successor_rank = 0
                for succ_id in successors:
                    succ_rank = compute_rank(succ_id)
                    # ç®€åŒ–çš„é€šä¿¡æˆæœ¬ä¼°è®¡
                    comm_cost = 1.0  # å®é™…åº”è¯¥æ ¹æ®ä»»åŠ¡é—´æ•°æ®é‡è®¡ç®—
                    max_successor_rank = max(max_successor_rank, succ_rank + comm_cost)

                upward_ranks[task_id] = avg_execution + max_successor_rank

            return upward_ranks[task_id]

        # ä»å…¥å£ä»»åŠ¡å¼€å§‹è®¡ç®—
        entry_tasks = self._get_entry_tasks(dag)
        for task_id in entry_tasks:
            compute_rank(task_id)

        return upward_ranks

    def _heft_processor_selection(self, dag, task_sequence: List[int]) -> Dict[int, int]:
        """HEFTå¤„ç†æœºé€‰æ‹©ï¼ˆæœ€æ—©å®Œæˆæ—¶é—´ï¼‰"""
        hardware_mapping = {}
        hardware_availability = {hw: 0.0 for hw in self.env.hardware_resources.keys()}

        for task_id in task_sequence:
            task = self._get_task_by_id(dag, task_id)
            best_hardware = None
            earliest_finish = float('inf')

            # ä¸ºä»»åŠ¡é€‰æ‹©æœ€æ—©å®Œæˆçš„å¤„ç†æœº
            for hw_type, hw_info in self.env.hardware_resources.items():
                # è®¡ç®—æœ€æ—©å¼€å§‹æ—¶é—´
                est = self._calculate_est(task_id, hw_type, hardware_availability, dag)

                # è®¡ç®—æ‰§è¡Œæ—¶é—´
                exec_time = task.computation_cost.get(hw_type, 10.0) if task.computation_cost else 10.0

                # å®Œæˆæ—¶é—´
                eft = est + exec_time

                if eft < earliest_finish:
                    earliest_finish = eft
                    best_hardware = hw_type

            # è®°å½•åˆ†é…
            if best_hardware is not None:
                hw_idx = list(self.env.hardware_resources.keys()).index(best_hardware)
                hardware_mapping[task_id] = hw_idx
                hardware_availability[best_hardware] = earliest_finish

        return hardware_mapping

    def _calculate_est(self, task_id: int, hw_type: str, hardware_availability: Dict, dag) -> float:
        """è®¡ç®—æœ€æ—©å¼€å§‹æ—¶é—´"""
        task = self._get_task_by_id(dag, task_id)

        # ç¡¬ä»¶å¯ç”¨æ—¶é—´
        hw_available = hardware_availability[hw_type]

        # ä¾èµ–ä»»åŠ¡çš„æœ€æ™šå®Œæˆæ—¶é—´
        est_from_dependencies = 0.0
        if task.data_dependencies:
            for dep_id in task.data_dependencies:
                dep_task = self._get_task_by_id(dag, dep_id)
                # ç®€åŒ–çš„é€šä¿¡æ—¶é—´ä¼°è®¡
                comm_time = 1.0  # å®é™…åº”æ ¹æ®ç¡¬ä»¶é—´é€šä¿¡æˆæœ¬è®¡ç®—
                est_from_dependencies = max(est_from_dependencies,
                                            hardware_availability.get(hw_type, 0) + comm_time)

        return max(hw_available, est_from_dependencies)

    def _get_successors(self, dag, task_id: int) -> List[int]:
        """è·å–åç»§ä»»åŠ¡"""
        successors = []
        for edge in dag.edges:
            if edge[0] == task_id:  # source == task_id
                successors.append(edge[1])  # target
        return successors

    def _get_entry_tasks(self, dag) -> List[int]:
        """è·å–å…¥å£ä»»åŠ¡ï¼ˆæ²¡æœ‰ä¾èµ–çš„ä»»åŠ¡ï¼‰"""
        all_tasks = set(node.node_id for node in dag.nodes)
        dependent_tasks = set()

        for edge in dag.edges:
            dependent_tasks.add(edge[1])  # ç›®æ ‡ä»»åŠ¡æœ‰ä¾èµ–

        entry_tasks = list(all_tasks - dependent_tasks)
        return entry_tasks

    def _get_task_by_id(self, dag, task_id: int):
        """æ ¹æ®IDè·å–ä»»åŠ¡èŠ‚ç‚¹"""
        for node in dag.nodes:
            if node.node_id == task_id:
                return node
        return None

    def _get_next_heft_task(self, task_sequence: List[int]) -> Optional[int]:
        """è·å–ä¸‹ä¸€ä¸ªå¯è°ƒåº¦çš„HEFTä»»åŠ¡"""
        for task_id in task_sequence:
            task = self.env._get_task_by_id(task_id)
            if (task and task['state'] == self.env.TaskState.WAITING and
                    self.env._check_task_dependencies(task)):
                return task_id
        return None

    def train_cpop(self, num_episodes: int = 100) -> Dict[str, Any]:
        """è®­ç»ƒCPOPç®—æ³•"""
        print("ğŸš€ å¼€å§‹CPOPåŸºçº¿æ€§èƒ½è¯„ä¼°...")

        results = {
            'makespans': [],
            'energy_consumptions': [],
            'load_balances': [],
            'deadline_satisfactions': [],
            'training_time': 0
        }

        start_time = time.time()

        for episode in tqdm(range(num_episodes), desc="CPOP"):
            dag = self.dag_generator.generate()
            metrics = self._run_cpop_scheduling(dag)

            results['makespans'].append(metrics['makespan'])
            results['energy_consumptions'].append(metrics['energy_consumption'])
            results['load_balances'].append(metrics['load_balance'])
            results['deadline_satisfactions'].append(metrics['deadline_satisfaction'])

        results['training_time'] = time.time() - start_time

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        results['avg_makespan'] = np.mean(results['makespans'])
        results['std_makespan'] = np.std(results['makespans'])
        results['avg_energy'] = np.mean(results['energy_consumptions'])
        results['avg_load_balance'] = np.mean(results['load_balances'])
        results['avg_deadline_satisfaction'] = np.mean(results['deadline_satisfactions'])

        self.baseline_performance['CPOP'] = results
        print(f"âœ… CPOPè¯„ä¼°å®Œæˆ - å¹³å‡å®Œæˆæ—¶é—´: {results['avg_makespan']:.2f} ms")

        return results

    def _run_cpop_scheduling(self, dag) -> Dict[str, float]:
        """è¿è¡ŒCPOPè°ƒåº¦ç®—æ³•"""
        # CPOPå®ç°ç±»ä¼¼HEFTï¼Œä½†å…³é”®è·¯å¾„ä»»åŠ¡åˆ†é…åˆ°ä¸“ç”¨å¤„ç†å™¨
        # è¿™é‡Œç®€åŒ–å®ç°ï¼Œå®é™…CPOPæ›´å¤æ‚
        return self._run_heft_scheduling(dag)

    def train_random(self, num_episodes: int = 100) -> Dict[str, Any]:
        """éšæœºè°ƒåº¦ç®—æ³•"""
        print("ğŸš€ å¼€å§‹éšæœºè°ƒåº¦ç®—æ³•è¯„ä¼°...")

        results = {
            'makespans': [],
            'energy_consumptions': [],
            'load_balances': [],
            'deadline_satisfactions': [],
            'training_time': 0
        }

        start_time = time.time()

        for episode in tqdm(range(num_episodes), desc="Random"):
            dag = self.dag_generator.generate()
            state = self.env.reset(dag)

            done = False
            while not done:
                # éšæœºé€‰æ‹©ç¡¬ä»¶
                available_actions = self.env.get_available_actions()
                action = np.random.choice(available_actions)

                state, reward, done, info = self.env.step(action)

            metrics = self.metrics_calculator.calculate_metrics(self.env)

            results['makespans'].append(metrics['makespan'])
            results['energy_consumptions'].append(metrics['energy_consumption'])
            results['load_balances'].append(metrics['load_balance'])
            results['deadline_satisfactions'].append(metrics['deadline_satisfaction'])

        results['training_time'] = time.time() - start_time

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        results['avg_makespan'] = np.mean(results['makespans'])
        results['std_makespan'] = np.std(results['makespans'])
        results['avg_energy'] = np.mean(results['energy_consumptions'])
        results['avg_load_balance'] = np.mean(results['load_balances'])
        results['avg_deadline_satisfaction'] = np.mean(results['deadline_satisfactions'])

        self.baseline_performance['Random'] = results
        print(f"âœ… éšæœºè°ƒåº¦è¯„ä¼°å®Œæˆ - å¹³å‡å®Œæˆæ—¶é—´: {results['avg_makespan']:.2f} ms")

        return results

    def run_all_baselines(self, num_episodes: int = 100) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰åŸºçº¿ç®—æ³•"""
        print("=" * 80)
        print("ğŸ¯ å¼€å§‹æ‰€æœ‰åŸºçº¿ç®—æ³•æ€§èƒ½è¯„ä¼°")
        print("=" * 80)

        # è¿è¡Œå„ç§åŸºçº¿ç®—æ³•
        self.train_heft(num_episodes)
        self.train_cpop(num_episodes)
        self.train_random(num_episodes)

        # ç”Ÿæˆæ¯”è¾ƒæŠ¥å‘Š
        self.generate_baseline_report()

        return self.baseline_performance

    def generate_baseline_report(self):
        """ç”ŸæˆåŸºçº¿ç®—æ³•æ€§èƒ½æŠ¥å‘Š"""
        if not self.baseline_performance:
            print("âš ï¸ æ²¡æœ‰å¯ç”¨çš„åŸºçº¿æ€§èƒ½æ•°æ®")
            return

        print("\n" + "=" * 80)
        print("ğŸ“Š åŸºçº¿ç®—æ³•æ€§èƒ½æ¯”è¾ƒæŠ¥å‘Š")
        print("=" * 80)

        # åˆ›å»ºæ¯”è¾ƒè¡¨æ ¼
        comparison_data = []

        for algo_name, results in self.baseline_performance.items():
            row = {
                'Algorithm': algo_name,
                'Avg Makespan': f"{results['avg_makespan']:.2f} Â± {results['std_makespan']:.2f}",
                'Avg Energy': f"{results['avg_energy']:.2f}",
                'Avg Load Balance': f"{results['avg_load_balance']:.3f}",
                'Avg Deadline Satisfaction': f"{results['avg_deadline_satisfaction']:.3f}",
                'Training Time (s)': f"{results['training_time']:.2f}"
            }
            comparison_data.append(row)

        # æ‰“å°è¡¨æ ¼
        df = pd.DataFrame(comparison_data)
        print("\næ€§èƒ½æ¯”è¾ƒ:")
        print(df.to_string(index=False))

        # ä¿å­˜ç»“æœ
        self._save_baseline_results()

        # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        self._plot_baseline_comparison()

    def _save_baseline_results(self):
        """ä¿å­˜åŸºçº¿ç»“æœ"""
        os.makedirs('results/baselines', exist_ok=True)

        # ä¿å­˜è¯¦ç»†ç»“æœ
        with open('results/baselines/baseline_performance.json', 'w') as f:
            # è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹
            serializable_results = {}
            for algo, results in self.baseline_performance.items():
                serializable_results[algo] = {
                    k: (v.tolist() if isinstance(v, np.ndarray) else v)
                    for k, v in results.items()
                }
            json.dump(serializable_results, f, indent=2)

        # ä¿å­˜æ‘˜è¦
        summary_data = []
        for algo, results in self.baseline_performance.items():
            summary_data.append({
                'algorithm': algo,
                'avg_makespan': results['avg_makespan'],
                'std_makespan': results['std_makespan'],
                'avg_energy': results['avg_energy'],
                'avg_load_balance': results['avg_load_balance'],
                'avg_deadline_satisfaction': results['avg_deadline_satisfaction'],
                'training_time': results['training_time']
            })

        df = pd.DataFrame(summary_data)
        df.to_csv('results/baselines/baseline_summary.csv', index=False)

        print("âœ… åŸºçº¿ç»“æœå·²ä¿å­˜è‡³ results/baselines/")

    def _plot_baseline_comparison(self):
        """ç»˜åˆ¶åŸºçº¿ç®—æ³•æ¯”è¾ƒå›¾"""
        if not self.baseline_performance:
            return

        algorithms = list(self.baseline_performance.keys())

        # åˆ›å»ºå¤šä¸ªå­å›¾
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))

        # Makespanæ¯”è¾ƒ
        makespans = [self.baseline_performance[algo]['avg_makespan'] for algo in algorithms]
        stds = [self.baseline_performance[algo]['std_makespan'] for algo in algorithms]

        bars = axes[0, 0].bar(algorithms, makespans, yerr=stds, capsize=5, alpha=0.7)
        axes[0, 0].set_title('å¹³å‡å®Œæˆæ—¶é—´æ¯”è¾ƒ')
        axes[0, 0].set_ylabel('å®Œæˆæ—¶é—´ (ms)')

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, makespans):
            axes[0, 0].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 5,
                            f'{value:.1f}', ha='center', va='bottom')

        # èƒ½è€—æ¯”è¾ƒ
        energies = [self.baseline_performance[algo]['avg_energy'] for algo in algorithms]
        axes[0, 1].bar(algorithms, energies, alpha=0.7, color='orange')
        axes[0, 1].set_title('å¹³å‡èƒ½è€—æ¯”è¾ƒ')
        axes[0, 1].set_ylabel('èƒ½è€—')

        # è´Ÿè½½å‡è¡¡æ¯”è¾ƒ
        load_balances = [self.baseline_performance[algo]['avg_load_balance'] for algo in algorithms]
        axes[1, 0].bar(algorithms, load_balances, alpha=0.7, color='green')
        axes[1, 0].set_title('å¹³å‡è´Ÿè½½å‡è¡¡æ¯”è¾ƒ')
        axes[1, 0].set_ylabel('è´Ÿè½½å‡è¡¡æŒ‡æ ‡')

        # æˆªæ­¢æ—¶é—´æ»¡è¶³ç‡æ¯”è¾ƒ
        deadlines = [self.baseline_performance[algo]['avg_deadline_satisfaction'] for algo in algorithms]
        axes[1, 1].bar(algorithms, deadlines, alpha=0.7, color='red')
        axes[1, 1].set_title('å¹³å‡æˆªæ­¢æ—¶é—´æ»¡è¶³ç‡æ¯”è¾ƒ')
        axes[1, 1].set_ylabel('æ»¡è¶³ç‡')

        plt.tight_layout()
        plt.savefig('results/baselines/baseline_comparison.png', dpi=300, bbox_inches='tight')
        plt.close()

        print("âœ… åŸºçº¿æ¯”è¾ƒå›¾è¡¨å·²ä¿å­˜")


def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡ŒåŸºçº¿ç®—æ³•è®­ç»ƒ"""
    import yaml

    # åŠ è½½é…ç½®
    with open('configs/default_config.yaml', 'r') as f:
        config = yaml.safe_load(f)

    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = BaselineTrainer(config)

    # è¿è¡Œæ‰€æœ‰åŸºçº¿ç®—æ³•
    results = trainer.run_all_baselines(num_episodes=50)

    print("\nğŸ‰ åŸºçº¿ç®—æ³•è®­ç»ƒå®Œæˆï¼")


if __name__ == "__main__":
    main()