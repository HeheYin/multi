import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from typing import Dict, List, Any, Optional
from tqdm import tqdm
import os
import json

from models.networks.embedded_modrl import EmbeddedMODRL
from models.networks.lightweight_st_embedding import LightweightSTEmbedding
from models.networks.lightweight_set_encoder import LightweightSetEncoder
from environments.embedded_scheduling_env import EmbeddedSchedulingEnvironment
from utils.metrics import SchedulingMetrics
from data.datasets.embedded_dag_generator import EmbeddedDAGGenerator


class AblationStudy:
    """æ¶ˆèå®éªŒç ”ç©¶"""

    def __init__(self, config):
        self.config = config
        self.metrics_calculator = SchedulingMetrics()
        self.dag_generator = EmbeddedDAGGenerator(config)
        self.results = {}

    def create_ablated_models(self, base_model_path: str) -> Dict[str, torch.nn.Module]:
        """åˆ›å»ºæ¶ˆèå®éªŒçš„å„ä¸ªå˜ä½“æ¨¡å‹"""
        models = {}

        # åŠ è½½åŸºç¡€æ¨¡å‹
        base_model = self._load_base_model(base_model_path)
        models['Full_Model'] = base_model

        # 1. æ— æ—¶ç©ºåµŒå…¥æ¨¡å‹ (ä»…ä½¿ç”¨åŸå§‹ç‰¹å¾)
        models['No_ST_Embedding'] = self._create_no_st_embedding_model(base_model)

        # 2. æ— å›¾æ³¨æ„åŠ›æ¨¡å‹ (æ›¿æ¢ä¸ºç®€å•çº¿æ€§å±‚)
        models['No_GAT'] = self._create_no_gat_model(base_model)

        # 3. æ— æ—¶åºæ¨¡å‹ (ç§»é™¤LSTM/GRU)
        models['No_Temporal'] = self._create_no_temporal_model(base_model)

        # 4. æ— Set Transformeræ¨¡å‹ (ä½¿ç”¨å¹³å‡æ± åŒ–)
        models['No_Set_Transformer'] = self._create_no_set_transformer_model(base_model)

        # 5. ä»…Makespanä¼˜åŒ– (å•ç›®æ ‡)
        models['Makespan_Only'] = self._create_single_objective_model(base_model, 'makespan')

        # 6. ä»…èƒ½è€—ä¼˜åŒ– (å•ç›®æ ‡)
        models['Energy_Only'] = self._create_single_objective_model(base_model, 'energy')

        print(f"âœ… æˆåŠŸåˆ›å»º {len(models)} ä¸ªæ¶ˆèå®éªŒæ¨¡å‹")
        return models

    def _load_base_model(self, model_path: str) -> EmbeddedMODRL:
        """åŠ è½½åŸºç¡€æ¨¡å‹"""
        model_config = self.config['model']
        model = EmbeddedMODRL(
            node_feature_dim=model_config['node_feature_dim'],
            hardware_feature_dim=model_config['hardware_feature_dim'],
            hidden_dim=model_config['hidden_dim'],
            num_hardware=model_config['num_hardware'],
            num_actions=model_config['num_actions']
        )

        checkpoint = torch.load(model_path, map_location='cpu')
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()

        return model

    def _create_no_st_embedding_model(self, base_model: EmbeddedMODRL) -> torch.nn.Module:
        """åˆ›å»ºæ— æ—¶ç©ºåµŒå…¥çš„æ¨¡å‹å˜ä½“"""

        class NoSTEmbeddingModel(torch.nn.Module):
            def __init__(self, base):
                super().__init__()
                self.base = base
                # æ›¿æ¢æ—¶ç©ºåµŒå…¥ä¸ºç®€å•çš„çº¿æ€§æŠ•å½±
                self.simple_embedding = torch.nn.Linear(
                    base.st_embedding.st_embedding[0].in_features,
                    base.st_embedding.st_embedding[0].out_features
                )

            def forward(self, node_features, adjacency_matrix, task_sequence, hardware_features):
                # ç®€å•çº¿æ€§æŠ•å½±ä»£æ›¿å¤æ‚æ—¶ç©ºåµŒå…¥
                task_embedding = self.simple_embedding(node_features.mean(dim=0))
                hardware_embedding = self.base.hardware_encoder(hardware_features)
                hardware_global = torch.mean(hardware_embedding, dim=0)

                state_embedding = torch.cat([task_embedding, hardware_global], dim=-1)

                value = self.base.value_stream(state_embedding)
                advantages = self.base.advantage_stream(state_embedding)
                q_values = value + (advantages - advantages.mean())

                return q_values

        return NoSTEmbeddingModel(base_model)

    def _create_no_gat_model(self, base_model: EmbeddedMODRL) -> torch.nn.Module:
        """åˆ›å»ºæ— å›¾æ³¨æ„åŠ›çš„æ¨¡å‹å˜ä½“"""

        class NoGATModel(torch.nn.Module):
            def __init__(self, base):
                super().__init__()
                self.base = base
                # ç§»é™¤GATï¼Œä»…ä¿ç•™ç®€å•çš„ç‰¹å¾æå–
                self.feature_extractor = torch.nn.Sequential(
                    torch.nn.Linear(
                        base.st_embedding.spatial_encoder.layers[0].in_features,
                        base.st_embedding.spatial_encoder.layers[0].out_features
                    ),
                    torch.nn.ReLU()
                )

            def forward(self, node_features, adjacency_matrix, task_sequence, hardware_features):
                # ç®€å•ç‰¹å¾æå–ä»£æ›¿GAT
                spatial_embeddings = self.feature_extractor(node_features)
                temporal_embeddings = self.base.st_embedding.temporal_encoder(
                    spatial_embeddings.unsqueeze(0), task_sequence)
                global_embedding = self.base.st_embedding.global_pool(
                    spatial_embeddings.transpose(0, 1)).squeeze()

                task_embedding = torch.cat([temporal_embeddings.squeeze(0), global_embedding], dim=-1)
                hardware_embedding = self.base.hardware_encoder(hardware_features)
                hardware_global = torch.mean(hardware_embedding, dim=0)

                state_embedding = torch.cat([task_embedding, hardware_global], dim=-1)

                value = self.base.value_stream(state_embedding)
                advantages = self.base.advantage_stream(state_embedding)
                q_values = value + (advantages - advantages.mean())

                return q_values

        return NoGATModel(base_model)

    def _create_no_temporal_model(self, base_model: EmbeddedMODRL) -> torch.nn.Module:
        """åˆ›å»ºæ— æ—¶åºç¼–ç çš„æ¨¡å‹å˜ä½“"""

        class NoTemporalModel(torch.nn.Module):
            def __init__(self, base):
                super().__init__()
                self.base = base

            def forward(self, node_features, adjacency_matrix, task_sequence, hardware_features):
                # è·³è¿‡æ—¶åºç¼–ç ï¼Œç›´æ¥ä½¿ç”¨ç©ºé—´ç‰¹å¾
                spatial_embeddings = self.base.st_embedding.spatial_encoder(
                    node_features, adjacency_matrix)
                global_embedding = self.base.st_embedding.global_pool(
                    spatial_embeddings.transpose(0, 1)).squeeze()

                # ä¸ä½¿ç”¨æ—¶åºç‰¹å¾
                task_embedding = global_embedding
                hardware_embedding = self.base.hardware_encoder(hardware_features)
                hardware_global = torch.mean(hardware_embedding, dim=0)

                state_embedding = torch.cat([task_embedding, hardware_global], dim=-1)

                value = self.base.value_stream(state_embedding)
                advantages = self.base.advantage_stream(state_embedding)
                q_values = value + (advantages - advantages.mean())

                return q_values

        return NoTemporalModel(base_model)

    def _create_no_set_transformer_model(self, base_model: EmbeddedMODRL) -> torch.nn.Module:
        """åˆ›å»ºæ— Set Transformerçš„æ¨¡å‹å˜ä½“"""

        class NoSetTransformerModel(torch.nn.Module):
            def __init__(self, base):
                super().__init__()
                self.base = base
                # ä½¿ç”¨å¹³å‡æ± åŒ–ä»£æ›¿Set Transformer
                self.simple_pooling = torch.nn.AdaptiveAvgPool1d(1)

            def forward(self, node_features, adjacency_matrix, task_sequence, hardware_features):
                task_embedding = self.base.st_embedding(
                    node_features, adjacency_matrix, task_sequence)

                # ç®€å•å¹³å‡æ± åŒ–ä»£æ›¿Set Transformer
                hardware_global = torch.mean(hardware_features, dim=0)

                state_embedding = torch.cat([task_embedding, hardware_global], dim=-1)

                value = self.base.value_stream(state_embedding)
                advantages = self.base.advantage_stream(state_embedding)
                q_values = value + (advantages - advantages.mean())

                return q_values

        return NoSetTransformerModel(base_model)

    def _create_single_objective_model(self, base_model: EmbeddedMODRL,
                                       objective: str) -> torch.nn.Module:
        """åˆ›å»ºå•ç›®æ ‡ä¼˜åŒ–çš„æ¨¡å‹å˜ä½“"""

        class SingleObjectiveModel(torch.nn.Module):
            def __init__(self, base, objective):
                super().__init__()
                self.base = base
                self.objective = objective

            def forward(self, node_features, adjacency_matrix, task_sequence, hardware_features):
                # ä½¿ç”¨ç›¸åŒçš„ç½‘ç»œç»“æ„ï¼Œä½†åœ¨è®­ç»ƒæ—¶ä½¿ç”¨å•ç›®æ ‡å¥–åŠ±
                return self.base(node_features, adjacency_matrix, task_sequence, hardware_features)

        return SingleObjectiveModel(base_model, objective)

    def run_ablation_study(self, test_dags: List, models: Dict[str, torch.nn.Module],
                           num_runs: int = 5) -> Dict[str, Dict[str, float]]:
        """
        è¿è¡Œæ¶ˆèå®éªŒ

        Args:
            test_dags: æµ‹è¯•DAGåˆ—è¡¨
            models: æ¨¡å‹å˜ä½“å­—å…¸
            num_runs: æ¯ä¸ªæ¨¡å‹åœ¨æ¯ä¸ªDAGä¸Šçš„è¿è¡Œæ¬¡æ•°
        """
        print("ğŸ”¬ å¼€å§‹æ¶ˆèå®éªŒ...")

        results = {}
        env = EmbeddedSchedulingEnvironment(self.config)

        for model_name, model in models.items():
            print(f"\nğŸ§ª æµ‹è¯•æ¨¡å‹å˜ä½“: {model_name}")
            model.eval()

            model_metrics = []

            for dag in tqdm(test_dags, desc=model_name, leave=False):
                dag_metrics = []

                for run in range(num_runs):
                    state = env.reset(dag)
                    done = False

                    while not done:
                        with torch.no_grad():
                            state_tensor = self._state_to_tensor(state, env)
                            q_values = model(*state_tensor)
                            action = torch.argmax(q_values).item()

                        state, reward, done, info = env.step(action)

                    metrics = self.metrics_calculator.calculate_metrics(env)
                    dag_metrics.append(metrics)

                avg_dag_metrics = self._average_metrics(dag_metrics)
                model_metrics.append(avg_dag_metrics)

            # è®¡ç®—æ¨¡å‹æ•´ä½“æŒ‡æ ‡
            results[model_name] = self._average_metrics(model_metrics)

        self.results = results
        self._save_ablation_results(results)
        return results

    def _state_to_tensor(self, state, env):
        """å°†çŠ¶æ€è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥å¼ é‡"""
        node_features = torch.tensor(state['node_features'], dtype=torch.float32)
        adjacency_matrix = torch.tensor(state['adjacency_matrix'], dtype=torch.float32)
        task_sequence = torch.tensor(state['task_sequence'], dtype=torch.long)
        hardware_features = torch.tensor(state['hardware_features'], dtype=torch.float32)

        return node_features, adjacency_matrix, task_sequence, hardware_features

    def _average_metrics(self, metrics_list: List[Dict]) -> Dict[str, float]:
        """è®¡ç®—æŒ‡æ ‡å¹³å‡å€¼"""
        if not metrics_list:
            return {}

        avg_metrics = {}
        for key in metrics_list[0].keys():
            values = [metrics[key] for metrics in metrics_list]
            avg_metrics[key] = np.mean(values)
            avg_metrics[f"{key}_std"] = np.std(values)

        return avg_metrics

    def _save_ablation_results(self, results: Dict):
        """ä¿å­˜æ¶ˆèå®éªŒç»“æœ"""
        os.makedirs('results/ablation', exist_ok=True)

        # ä¿å­˜ä¸ºCSV
        df_data = []
        for model_name, metrics in results.items():
            row = {'Model_Variant': model_name}
            row.update(metrics)
            df_data.append(row)

        df = pd.DataFrame(df_data)
        df.to_csv('results/ablation/ablation_results.csv', index=False)

        # ä¿å­˜ä¸ºJSON
        with open('results/ablation/ablation_results.json', 'w') as f:
            json.dump(results, f, indent=2)

    def analyze_component_importance(self) -> Dict[str, float]:
        """åˆ†æå„ç»„ä»¶çš„é‡è¦æ€§"""
        if not self.results or 'Full_Model' not in self.results:
            print("âš ï¸ éœ€è¦å…ˆè¿è¡Œæ¶ˆèå®éªŒ")
            return {}

        full_model_performance = self.results['Full_Model']['makespan']
        importance_scores = {}

        for model_name, metrics in self.results.items():
            if model_name != 'Full_Model':
                performance_drop = metrics['makespan'] - full_model_performance
                importance_scores[model_name] = performance_drop

        # æŒ‰é‡è¦æ€§æ’åº
        importance_scores = dict(sorted(
            importance_scores.items(),
            key=lambda x: x[1],
            reverse=True
        ))

        print("\nğŸ” ç»„ä»¶é‡è¦æ€§åˆ†æ:")
        print("-" * 40)
        for component, importance in importance_scores.items():
            print(f"{component:20}: {importance:+.4f}")

        return importance_scores

    def generate_ablation_report(self):
        """ç”Ÿæˆæ¶ˆèå®éªŒæŠ¥å‘Š"""
        if not self.results:
            print("âš ï¸ æ²¡æœ‰å¯ç”¨çš„ç»“æœï¼Œè¯·å…ˆè¿è¡Œæ¶ˆèå®éªŒ")
            return

        print("\n" + "=" * 80)
        print("ğŸ”¬ æ¶ˆèå®éªŒæŠ¥å‘Š")
        print("=" * 80)

        # ä¸»è¦æŒ‡æ ‡æ¯”è¾ƒ
        main_metrics = ['makespan', 'energy_consumption', 'load_balance', 'deadline_satisfaction']

        for metric in main_metrics:
            if metric in self.results['Full_Model']:
                print(f"\nğŸ“Š {metric.replace('_', ' ').title()} æ¯”è¾ƒ:")
                print("-" * 50)

                baseline_value = self.results['Full_Model'][metric]

                for model_name, metrics in self.results.items():
                    value = metrics[metric]
                    change = ((value - baseline_value) / baseline_value) * 100
                    change_symbol = "+" if change > 0 else ""
                    print(f"{model_name:25}: {value:.4f} ({change_symbol}{change:+.1f}%)")

        # ç»„ä»¶é‡è¦æ€§åˆ†æ
        self.analyze_component_importance()

        # ç”Ÿæˆå¯è§†åŒ–
        self._generate_ablation_plots()

    def _generate_ablation_plots(self):
        """ç”Ÿæˆæ¶ˆèå®éªŒå¯è§†åŒ–å›¾è¡¨"""
        if not self.results:
            return

        metrics_to_plot = ['makespan', 'energy_consumption', 'load_balance']

        for metric in metrics_to_plot:
            if metric in self.results['Full_Model']:
                plt.figure(figsize=(12, 6))

                model_names = list(self.results.keys())
                values = [self.results[name][metric] for name in model_names]

                bars = plt.bar(model_names, values, alpha=0.7)
                plt.title(f'Ablation Study - {metric.replace("_", " ").title()}')
                plt.ylabel(metric.replace('_', ' ').title())
                plt.xticks(rotation=45, ha='right')

                # æ·»åŠ æ•°å€¼æ ‡ç­¾
                for bar, value in zip(bars, values):
                    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,
                             f'{value:.3f}', ha='center', va='bottom')

                plt.tight_layout()
                plt.savefig(f'results/ablation/{metric}_ablation.png', dpi=300, bbox_inches='tight')
                plt.close()

        print("âœ… æ¶ˆèå®éªŒå›¾è¡¨å·²ä¿å­˜è‡³ results/ablation/")