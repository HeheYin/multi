import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from typing import Dict, List, Any
from tqdm import tqdm
import time
import os

from models.core.embedded_dag import EmbeddedDAG
from environments.embedded_scheduling_env import EmbeddedSchedulingEnvironment
from agents.d3qn_agent import D3QNAgent
from utils.metrics import SchedulingMetrics
from utils.visualization import plot_comparison_results


class BaselineComparator:
    """åŸºçº¿ç®—æ³•æ¯”è¾ƒå™¨"""

    def __init__(self, config):
        self.config = config
        self.metrics_calculator = SchedulingMetrics()
        self.results = {}

        # åˆå§‹åŒ–åŸºçº¿ç®—æ³•
        self.baselines = self._initialize_baselines()

    def _initialize_baselines(self) -> Dict[str, Any]:
        """åˆå§‹åŒ–æ‰€æœ‰åŸºçº¿ç®—æ³•"""
        baselines = {}

        # HEFTç®—æ³•
        baselines['HEFT'] = HEFTBaseline()

        # CPOPç®—æ³•
        baselines['CPOP'] = CPOPBaseline()

        # EDFç®—æ³•ï¼ˆåµŒå…¥å¼å®æ—¶è°ƒåº¦ï¼‰
        baselines['EDF'] = EDFBaseline()

        # RMç®—æ³•ï¼ˆé€Ÿç‡å•è°ƒè°ƒåº¦ï¼‰
        baselines['RM'] = RMBaseline()

        # éšæœºè°ƒåº¦
        baselines['Random'] = RandomBaseline()

        return baselines

    def load_trained_model(self, model_path: str):
        """åŠ è½½è®­ç»ƒå¥½çš„MODRLæ¨¡å‹"""
        from models.networks.embedded_modrl import EmbeddedMODRL

        model_config = self.config['model']
        self.modrl_model = EmbeddedMODRL(
            node_feature_dim=model_config['node_feature_dim'],
            hardware_feature_dim=model_config['hardware_feature_dim'],
            hidden_dim=model_config['hidden_dim'],
            num_hardware=model_config['num_hardware'],
            num_actions=model_config['num_actions']
        )

        checkpoint = torch.load(model_path, map_location='cpu')
        self.modrl_model.load_state_dict(checkpoint['model_state_dict'])
        self.modrl_model.eval()

        print(f"âœ… æˆåŠŸåŠ è½½MODRLæ¨¡å‹: {model_path}")

    def run_comparison(self, test_datasets: Dict[str, List[EmbeddedDAG]],
                       num_runs: int = 10) -> Dict[str, Dict[str, float]]:
        """
        è¿è¡Œå®Œæ•´çš„æ¯”è¾ƒå®éªŒ

        Args:
            test_datasets: æµ‹è¯•æ•°æ®é›† {'dataset_name': [dag1, dag2, ...]}
            num_runs: æ¯ä¸ªç®—æ³•åœ¨æ¯ä¸ªDAGä¸Šçš„è¿è¡Œæ¬¡æ•°
        """
        print("ğŸš€ å¼€å§‹åŸºçº¿ç®—æ³•æ¯”è¾ƒå®éªŒ...")

        all_results = {}

        for dataset_name, dags in test_datasets.items():
            print(f"\nğŸ“Š æµ‹è¯•æ•°æ®é›†: {dataset_name}, DAGæ•°é‡: {len(dags)}")
            dataset_results = {}

            # æµ‹è¯•æ‰€æœ‰åŸºçº¿ç®—æ³•
            for baseline_name, baseline in self.baselines.items():
                print(f"  æ­£åœ¨æµ‹è¯• {baseline_name}...")
                baseline_metrics = self._evaluate_baseline(
                    baseline, dags, num_runs, baseline_name)
                dataset_results[baseline_name] = baseline_metrics

            # æµ‹è¯•MODRLæ¨¡å‹
            if hasattr(self, 'modrl_model'):
                print("  æ­£åœ¨æµ‹è¯• MODRL...")
                modrl_metrics = self._evaluate_modrl(dags, num_runs)
                dataset_results['MODRL'] = modrl_metrics

            all_results[dataset_name] = dataset_results

            # ä¿å­˜å½“å‰æ•°æ®é›†ç»“æœ
            self._save_dataset_results(dataset_name, dataset_results)

        self.results = all_results
        return all_results

    def _evaluate_baseline(self, baseline, dags: List[EmbeddedDAG],
                           num_runs: int, baseline_name: str) -> Dict[str, float]:
        """è¯„ä¼°å•ä¸ªåŸºçº¿ç®—æ³•"""
        env = EmbeddedSchedulingEnvironment(self.config)
        all_metrics = []

        for dag in tqdm(dags, desc=f"{baseline_name}", leave=False):
            dag_metrics = []

            for run in range(num_runs):
                # é‡ç½®ç¯å¢ƒ
                state = env.reset(dag)
                done = False

                while not done:
                    # åŸºçº¿ç®—æ³•å†³ç­–
                    action = baseline.schedule(env.current_state, env.available_hardware)
                    state, reward, done, info = env.step(action)

                # æ”¶é›†æŒ‡æ ‡
                metrics = self.metrics_calculator.calculate_metrics(env)
                dag_metrics.append(metrics)

            # è®¡ç®—DAGçš„å¹³å‡æŒ‡æ ‡
            avg_metrics = self._average_metrics(dag_metrics)
            all_metrics.append(avg_metrics)

        # è®¡ç®—æ•´ä½“å¹³å‡æŒ‡æ ‡
        return self._average_metrics(all_metrics)

    def _evaluate_modrl(self, dags: List[EmbeddedDAG], num_runs: int) -> Dict[str, float]:
        """è¯„ä¼°MODRLæ¨¡å‹"""
        env = EmbeddedSchedulingEnvironment(self.config)
        all_metrics = []

        for dag in tqdm(dags, desc="MODRL", leave=False):
            dag_metrics = []

            for run in range(num_runs):
                state = env.reset(dag)
                done = False

                while not done:
                    # MODRLæ¨¡å‹å†³ç­–
                    with torch.no_grad():
                        state_tensor = self._state_to_tensor(state, env)
                        q_values = self.modrl_model(*state_tensor)
                        action = torch.argmax(q_values).item()

                    state, reward, done, info = env.step(action)

                metrics = self.metrics_calculator.calculate_metrics(env)
                dag_metrics.append(metrics)

            avg_metrics = self._average_metrics(dag_metrics)
            all_metrics.append(avg_metrics)

        return self._average_metrics(all_metrics)

    def _state_to_tensor(self, state, env):
        """å°†çŠ¶æ€è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥å¼ é‡"""
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„çŠ¶æ€è¡¨ç¤ºæ¥å®ç°
        node_features = torch.tensor(state['node_features'], dtype=torch.float32)
        adjacency_matrix = torch.tensor(state['adjacency_matrix'], dtype=torch.float32)
        task_sequence = torch.tensor(state['task_sequence'], dtype=torch.long)
        hardware_features = torch.tensor(state['hardware_features'], dtype=torch.float32)

        return node_features, adjacency_matrix, task_sequence, hardware_features

    def _average_metrics(self, metrics_list: List[Dict]) -> Dict[str, float]:
        """è®¡ç®—æŒ‡æ ‡å¹³å‡å€¼"""
        if not metrics_list:
            return {}

        avg_metrics = {}
        for key in metrics_list[0].keys():
            values = [metrics[key] for metrics in metrics_list]
            avg_metrics[key] = np.mean(values)
            avg_metrics[f"{key}_std"] = np.std(values)

        return avg_metrics

    def _save_dataset_results(self, dataset_name: str, results: Dict):
        """ä¿å­˜æ•°æ®é›†ç»“æœåˆ°æ–‡ä»¶"""
        os.makedirs('results/comparison', exist_ok=True)

        # ä¿å­˜ä¸ºCSV
        df_data = []
        for algo, metrics in results.items():
            row = {'Algorithm': algo}
            row.update(metrics)
            df_data.append(row)

        df = pd.DataFrame(df_data)
        df.to_csv(f'results/comparison/{dataset_name}_comparison.csv', index=False)

        # ä¿å­˜ä¸ºJSON
        import json
        with open(f'results/comparison/{dataset_name}_comparison.json', 'w') as f:
            json.dump(results, f, indent=2)

    def generate_report(self):
        """ç”Ÿæˆæ¯”è¾ƒå®éªŒæŠ¥å‘Š"""
        if not self.results:
            print("âš ï¸ æ²¡æœ‰å¯ç”¨çš„ç»“æœï¼Œè¯·å…ˆè¿è¡Œæ¯”è¾ƒå®éªŒ")
            return

        print("\n" + "=" * 80)
        print("ğŸ“ˆ åŸºçº¿ç®—æ³•æ¯”è¾ƒå®éªŒæŠ¥å‘Š")
        print("=" * 80)

        for dataset_name, algorithms in self.results.items():
            print(f"\nğŸ“Š æ•°æ®é›†: {dataset_name}")
            print("-" * 50)

            # åˆ›å»ºæ¯”è¾ƒè¡¨æ ¼
            metrics_to_show = ['makespan', 'energy_consumption', 'load_balance', 'deadline_satisfaction']

            for metric in metrics_to_show:
                if metric in list(algorithms.values())[0]:
                    print(f"\n{metric.replace('_', ' ').title()}:")
                    for algo, metrics in algorithms.items():
                        value = metrics.get(metric, 'N/A')
                        if isinstance(value, float):
                            print(f"  {algo:15}: {value:.4f}")
                        else:
                            print(f"  {algo:15}: {value}")

        # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        self._generate_comparison_plots()

    def _generate_comparison_plots(self):
        """ç”Ÿæˆæ¯”è¾ƒç»“æœå¯è§†åŒ–å›¾è¡¨"""
        for dataset_name, algorithms in self.results.items():
            plot_comparison_results(algorithms, dataset_name)


# åŸºçº¿ç®—æ³•å®ç°
class HEFTBaseline:
    """HEFTç®—æ³•å®ç°"""

    def schedule(self, state, available_hardware):
        # ç®€åŒ–çš„HEFTå®ç°
        # å®é™…å®ç°éœ€è¦è®¡ç®— upward rank å’Œé€‰æ‹©æœ€æ—©å®Œæˆæ—¶é—´çš„å¤„ç†å™¨
        current_task = state['current_task']
        task_priority = state['task_priorities'][current_task]

        # é€‰æ‹©è´Ÿè½½æœ€ä½çš„ç¡¬ä»¶
        hardware_loads = state['hardware_loads']
        best_hardware = np.argmin(hardware_loads)

        return best_hardware


class CPOPBaseline:
    """CPOPç®—æ³•å®ç°"""

    def schedule(self, state, available_hardware):
        # ç®€åŒ–çš„CPOPå®ç°
        current_task = state['current_task']
        is_critical = state.get('is_critical_path', {}).get(current_task, False)

        if is_critical:
            # å…³é”®è·¯å¾„ä»»åŠ¡åˆ†é…åˆ°ä¸“ç”¨å¤„ç†å™¨
            return 0  # å‡è®¾å¤„ç†å™¨0æ˜¯ä¸“ç”¨å¤„ç†å™¨
        else:
            # éå…³é”®è·¯å¾„ä½¿ç”¨HEFTç­–ç•¥
            hardware_loads = state['hardware_loads']
            return np.argmin(hardware_loads)


class EDFBaseline:
    """æœ€æ—©æˆªæ­¢æ—¶é—´ä¼˜å…ˆç®—æ³•"""

    def schedule(self, state, available_hardware):
        current_task = state['current_task']
        deadlines = state.get('task_deadlines', {})

        # ä¼˜å…ˆåˆ†é…æˆªæ­¢æ—¶é—´æœ€æ—©çš„ä»»åŠ¡åˆ°å¯ç”¨ç¡¬ä»¶
        task_deadline = deadlines.get(current_task, float('inf'))

        # é€‰æ‹©æœ€æ—©å¯ç”¨çš„ç¡¬ä»¶
        hardware_availability = state['hardware_availability']
        best_hardware = np.argmin(hardware_availability)

        return best_hardware


class RMBaseline:
    """é€Ÿç‡å•è°ƒè°ƒåº¦ç®—æ³•"""

    def schedule(self, state, available_hardware):
        current_task = state['current_task']
        task_periods = state.get('task_periods', {})

        # å‘¨æœŸè¶ŠçŸ­ï¼Œä¼˜å…ˆçº§è¶Šé«˜
        task_period = task_periods.get(current_task, float('inf'))
        priority = 1.0 / task_period if task_period > 0 else 0

        # åˆ†é…åˆ°è´Ÿè½½åˆé€‚çš„ç¡¬ä»¶
        hardware_loads = state['hardware_loads']
        best_hardware = np.argmin(hardware_loads)

        return best_hardware


class RandomBaseline:
    """éšæœºè°ƒåº¦ç®—æ³•"""

    def schedule(self, state, available_hardware):
        return np.random.randint(0, len(available_hardware))